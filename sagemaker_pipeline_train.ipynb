{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318715f4-6562-4309-9f7a-d57ab0e22dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3 \n",
    "import pandas as pd \n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession \n",
    "\n",
    "s3_client = boto3.resource('s3') \n",
    "pipeline_name = f\"sagemaker-mlops-train-pipeline\" \n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name \n",
    "role = sagemaker.get_execution_role() \n",
    "pipeline_session = PipelineSession() \n",
    "default_bucket = sagemaker_session.default_bucket() \n",
    "model_package_group_name = f\"ChurnModelPackageGroup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906984b1-e235-4b4c-b647-50c40ada9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ( \n",
    " ParameterInteger, \n",
    " ParameterString, \n",
    " ParameterFloat) \n",
    "\n",
    "auc_score_threshold = 0.75 \n",
    "base_job_prefix = \"churn-example\"\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString( name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\") \n",
    "training_instance_type = ParameterString( name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\") \n",
    "input_data = \"storedata_total.csv\" \n",
    "model_approval_status = ParameterString( name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2979e913-332a-464a-bdfc-ef2241341085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-04 12:03:09--  https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/dataset/storedata_total.xlsx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2713209 (2.6M) [application/octet-stream]\n",
      "Saving to: ‘storedata_total.xlsx’\n",
      "\n",
      "storedata_total.xls 100%[===================>]   2.59M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2025-06-04 12:03:10 (260 MB/s) - ‘storedata_total.xlsx’ saved [2713209/2713209]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/dataset/storedata_total.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb8b368-373a-4bc9-bb1e-19e6fd130eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "! pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c63a31-04e8-407d-9ad3-dd327450ee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "store_data = pd.read_excel(\"storedata_total.xlsx\") \n",
    "store_data.to_csv(\"storedata_total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f398c5-7f35-4ebf-bbbd-ebcac67cd24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-04 12:05:10--  https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/preprocess-churn.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2156 (2.1K) [text/plain]\n",
      "Saving to: ‘preprocess-churn.py’\n",
      "\n",
      "preprocess-churn.py 100%[===================>]   2.11K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-06-04 12:05:10 (42.8 MB/s) - ‘preprocess-churn.py’ saved [2156/2156]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/preprocess-churn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b404277a-c7c5-4f21-a799-cd421ea53cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtempfile\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mnumpy\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mpandas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mdatetime\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mdt\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    base_dir = \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Read Data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df = pd.read_csv(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/input/storedata_total.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# convert created column to datetime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df[\u001b[33m\"\u001b[39;49;00m\u001b[33mcreated\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = pd.to_datetime(df[\u001b[33m\"\u001b[39;49;00m\u001b[33mcreated\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Convert firstorder and lastorder to datetime datatype\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df[\u001b[33m\"\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = pd.to_datetime(df[\u001b[33m\"\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],errors=\u001b[33m'\u001b[39;49;00m\u001b[33mcoerce\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    df[\u001b[33m\"\u001b[39;49;00m\u001b[33mlastorder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = pd.to_datetime(df[\u001b[33m\"\u001b[39;49;00m\u001b[33mlastorder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],errors=\u001b[33m'\u001b[39;49;00m\u001b[33mcoerce\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Drop Rows with Null Values\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df = df.dropna()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Create column which gives the days between the last order and the first order\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df[\u001b[33m'\u001b[39;49;00m\u001b[33mfirst_last_days_diff\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = (df[\u001b[33m'\u001b[39;49;00m\u001b[33mlastorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] - df[\u001b[33m'\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).dt.days\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Create column which gives the days between the customer record was created and the first order\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df[\u001b[33m'\u001b[39;49;00m\u001b[33mcreated_first_days_diff\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = (df[\u001b[33m'\u001b[39;49;00m\u001b[33mcreated\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] - df[\u001b[33m'\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).dt.days\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Drop columns\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mcustid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcreated\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mfirstorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mlastorder\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m, inplace=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Apply one hot encoding on favday and city columns\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df = pd.get_dummies(df, prefix=[\u001b[33m'\u001b[39;49;00m\u001b[33mfavday\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], columns=[\u001b[33m'\u001b[39;49;00m\u001b[33mfavday\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Split into train, validation and test datasets\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    y = df.pop(\u001b[33m\"\u001b[39;49;00m\u001b[33mretained\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    X_pre = df\u001b[37m\u001b[39;49;00m\n",
      "    y_pre = y.to_numpy().reshape(\u001b[36mlen\u001b[39;49;00m(y), \u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    X = np.concatenate((y_pre, X_pre), axis=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    np.random.shuffle(X)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Split in Train, Test and Validation Datasets\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train, validation, test = np.split(X, [\u001b[36mint\u001b[39;49;00m(\u001b[34m.7\u001b[39;49;00m*\u001b[36mlen\u001b[39;49;00m(X)), \u001b[36mint\u001b[39;49;00m(\u001b[34m.85\u001b[39;49;00m*\u001b[36mlen\u001b[39;49;00m(X))])\u001b[37m\u001b[39;49;00m\n",
      "    train_rows = np.shape(train)[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    validation_rows = np.shape(validation)[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    test_rows = np.shape(test)[\u001b[34m0\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    train = pd.DataFrame(train)\u001b[37m\u001b[39;49;00m\n",
      "    test = pd.DataFrame(test)\u001b[37m\u001b[39;49;00m\n",
      "    validation = pd.DataFrame(validation)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Convert the label column to integer\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train[\u001b[34m0\u001b[39;49;00m] = train[\u001b[34m0\u001b[39;49;00m].astype(\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    test[\u001b[34m0\u001b[39;49;00m] = test[\u001b[34m0\u001b[39;49;00m].astype(\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    validation[\u001b[34m0\u001b[39;49;00m] = validation[\u001b[34m0\u001b[39;49;00m].astype(\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Save the Dataframes as csv files\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train.to_csv(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/train/train.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, header=\u001b[34mFalse\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    validation.to_csv(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/validation/validation.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, header=\u001b[34mFalse\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    test.to_csv(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/test/test.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, header=\u001b[34mFalse\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize \"preprocess-churn.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc25c1c-cf22-408c-9b68-0584cf0f49e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define Processing Step for Feature Engineering\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "framework_version = \"1.0-1\"\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-churn-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "      ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\",\\\n",
    "                         destination=f\"s3://{default_bucket}/output/train\" ),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\",\\\n",
    "                        destination=f\"s3://{default_bucket}/output/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\",\\\n",
    "                        destination=f\"s3://{default_bucket}/output/test\")\n",
    "    ],\n",
    "    code=f\"preprocess-churn.py\",\n",
    ")\n",
    "step_process = ProcessingStep(name=\"ChurnModelProcess\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fb9eb0-0cab-45d6-81db-a3ba6232a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "fixed_hyperparameters = {\n",
    "\"eval_metric\":\"auc\",\n",
    "\"objective\":\"binary:logistic\",\n",
    "\"num_round\":\"100\",\n",
    "\"rate_drop\":\"0.3\",\n",
    "\"tweedie_variance_power\":\"1.4\"\n",
    "}\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    hyperparameters=fixed_hyperparameters,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"churn-train\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b5a173-3637-4754-85c5-c9bc7b63989c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_ranges = {\n",
    "\"eta\": ContinuousParameter(0, 1),\n",
    "\"min_child_weight\": ContinuousParameter(1, 10),\n",
    "\"alpha\": ContinuousParameter(0, 2),\n",
    "\"max_depth\": IntegerParameter(1, 10),\n",
    "}\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_train,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=2,\n",
    ")\n",
    "\n",
    "hpo_args = tuner.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name=\"ChurnHyperParameterTuning\",\n",
    "    step_args=hpo_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017007d2-dc49-4f8a-8d9e-39ff7f1707d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-04 12:06:39--  https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/evaluate-churn.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1309 (1.3K) [text/plain]\n",
      "Saving to: ‘evaluate-churn.py’\n",
      "\n",
      "evaluate-churn.py   100%[===================>]   1.28K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-06-04 12:06:39 (107 MB/s) - ‘evaluate-churn.py’ saved [1309/1309]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/manifoldailearning/mlops-with-aws-datascientists/main/Section-16-mlops-pipeline/evaluate-churn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5e27c6-7c54-45b3-bc4f-8fd694d33a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mpathlib\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mpickle\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtarfile\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mjoblib\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mnumpy\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mpandas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mxgboost\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mdatetime\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mas\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mdt\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m roc_curve,auc\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:   \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Read Model Tar File\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model_path = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/model/model.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m tarfile.open(model_path) \u001b[34mas\u001b[39;49;00m tar:\u001b[37m\u001b[39;49;00m\n",
      "        tar.extractall(path=\u001b[33m\"\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model = pickle.load(\u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mxgboost-model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Read Test Data using which we evaluate the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    test_path = \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/test/test.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    df = pd.read_csv(test_path, header=\u001b[34mNone\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    y_test = df.iloc[:, \u001b[34m0\u001b[39;49;00m].to_numpy()\u001b[37m\u001b[39;49;00m\n",
      "    df.drop(df.columns[\u001b[34m0\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m, inplace=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    X_test = xgboost.DMatrix(df.values)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Run Predictions\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    predictions = model.predict(X_test)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Evaluate Predictions\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\u001b[37m\u001b[39;49;00m\n",
      "    auc_score = auc(fpr, tpr)\u001b[37m\u001b[39;49;00m\n",
      "    report_dict = {\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mclassification_metrics\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mauc_score\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: {\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: auc_score,\u001b[37m\u001b[39;49;00m\n",
      "            },\u001b[37m\u001b[39;49;00m\n",
      "        },\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Save Evaluation Report\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    output_dir = \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/evaluation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    pathlib.Path(output_dir).mkdir(parents=\u001b[34mTrue\u001b[39;49;00m, exist_ok=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    evaluation_path = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/evaluation.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(evaluation_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\n",
      "        f.write(json.dumps(report_dict))\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize \"evaluate-churn.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b61159-488c-4a3b-9716-2e8d94f2079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define model evaluation step to evaluate the trained model\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-churn-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "eval_args = script_eval.run(\n",
    "     inputs=[\n",
    "            ProcessingInput(\n",
    "                source=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=default_bucket,prefix=\"output\"),\n",
    "                destination=\"/opt/ml/processing/model\"\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\"\n",
    "            )\n",
    "        ],\n",
    "    outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\\\n",
    "                             destination=f\"s3://{default_bucket}/output/evaluation\"),\n",
    "        ],\n",
    "    code=f\"evaluate-churn.py\",\n",
    ")\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"ChurnEvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"ChurnEvalModel\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "100d4089-2ee5-475a-b33f-5ab075fee9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "/opt/conda/lib/python3.12/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import Model\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=default_bucket,prefix=\"output\"),\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "step_register = ModelStep(name=\"ChurnRegisterModel\", step_args=register_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1d0453f-51bd-43ae-9b9c-7091b61971ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.auc_score.value\",\n",
    "    ),\n",
    "    right=auc_score_threshold,\n",
    ")\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCScoreChurnEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b534d4a-3927-4f89-a603-4430ccb443fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Version': '2020-12-01', 'Metadata': {}, 'Parameters': [{'Name': 'ProcessingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1}, {'Name': 'ProcessingInstanceType', 'Type': 'String', 'DefaultValue': 'ml.m5.xlarge'}, {'Name': 'TrainingInstanceType', 'Type': 'String', 'DefaultValue': 'ml.m5.xlarge'}, {'Name': 'ModelApprovalStatus', 'Type': 'String', 'DefaultValue': 'PendingManualApproval'}], 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'}, 'TrialName': {'Get': 'Execution.PipelineExecutionId'}}, 'Steps': [{'Name': 'ChurnModelProcess', 'Type': 'Processing', 'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge', 'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'}, 'VolumeSizeInGB': 30}}, 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/preprocess-churn.py']}, 'RoleArn': 'arn:aws:iam::640168443051:role/service-role/AmazonSageMaker-ExecutionRole-20250523T211400', 'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-640168443051/sagemaker-mlops-train-pipeline/ChurnModelProcess/input/input-1/storedata_total.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-640168443051/sagemaker-mlops-train-pipeline/code/750df2449ecdbd5183671d6120028c588fb4e3db2e788a7609c70f0b47bea3e5/preprocess-churn.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-640168443051/output/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-640168443051/output/validation', 'LocalPath': '/opt/ml/processing/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-640168443051/output/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]}}}, {'Name': 'ChurnHyperParameterTuning', 'Type': 'Tuning', 'Arguments': {'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian', 'ResourceLimits': {'MaxNumberOfTrainingJobs': 2, 'MaxParallelTrainingJobs': 2}, 'TrainingJobEarlyStoppingType': 'Off', 'HyperParameterTuningJobObjective': {'Type': 'Maximize', 'MetricName': 'validation:auc'}, 'ParameterRanges': {'ContinuousParameterRanges': [{'Name': 'eta', 'MinValue': '0', 'MaxValue': '1', 'ScalingType': 'Auto'}, {'Name': 'min_child_weight', 'MinValue': '1', 'MaxValue': '10', 'ScalingType': 'Auto'}, {'Name': 'alpha', 'MinValue': '0', 'MaxValue': '2', 'ScalingType': 'Auto'}], 'CategoricalParameterRanges': [], 'IntegerParameterRanges': [{'Name': 'max_depth', 'MinValue': '1', 'MaxValue': '10', 'ScalingType': 'Auto'}]}}, 'TrainingJobDefinition': {'StaticHyperParameters': {'eval_metric': 'auc', 'objective': 'binary:logistic', 'num_round': '100', 'rate_drop': '0.3', 'tweedie_variance_power': '1.4'}, 'RoleArn': 'arn:aws:iam::640168443051:role/service-role/AmazonSageMaker-ExecutionRole-20250523T211400', 'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-640168443051/output'}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'HyperParameterTuningResourceConfig': {'InstanceCount': 1, 'InstanceType': {'Get': 'Parameters.TrainingInstanceType'}, 'VolumeSizeInGB': 30}, 'AlgorithmSpecification': {'TrainingInputMode': 'File', 'TrainingImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3'}, 'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"}, 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv', 'ChannelName': 'train'}, {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri\"}, 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv', 'ChannelName': 'validation'}]}}}, {'Name': 'ChurnEvalModel', 'Type': 'Processing', 'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'}, 'InstanceCount': 1, 'VolumeSizeInGB': 30}}, 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/evaluate-churn.py']}, 'RoleArn': 'arn:aws:iam::640168443051:role/service-role/AmazonSageMaker-ExecutionRole-20250523T211400', 'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': {'Std:Join': {'On': '/', 'Values': ['s3:/', 'sagemaker-us-east-1-640168443051', 'output', {'Get': 'Steps.ChurnHyperParameterTuning.TrainingJobSummaries[0].TrainingJobName'}, 'output/model.tar.gz']}}, 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"}, 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-640168443051/sagemaker-mlops-train-pipeline/code/3158cddf85a63c365e117c1fa2ecf663e6ac0d2c8609fe41eb58e8923a0d0011/evaluate-churn.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-640168443051/output/evaluation', 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}}]}}, 'PropertyFiles': [{'PropertyFileName': 'ChurnEvaluationReport', 'OutputName': 'evaluation', 'FilePath': 'evaluation.json'}]}, {'Name': 'CheckAUCScoreChurnEvaluation', 'Type': 'Condition', 'Arguments': {'Conditions': [{'Type': 'GreaterThan', 'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.ChurnEvalModel.PropertyFiles.ChurnEvaluationReport'}, 'Path': 'classification_metrics.auc_score.value'}}, 'RightValue': 0.75}], 'IfSteps': [{'Name': 'ChurnRegisterModel-RegisterModel', 'Type': 'RegisterModel', 'Arguments': {'ModelPackageGroupName': 'ChurnModelPackageGroup', 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json', 'S3Uri': 's3://sagemaker-us-east-1-640168443051/output/evaluation/evaluation.json'}}, 'Bias': {}, 'Explainability': {}}, 'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3', 'Environment': {}, 'ModelDataUrl': {'Std:Join': {'On': '/', 'Values': ['s3:/', 'sagemaker-us-east-1-640168443051', 'output', {'Get': 'Steps.ChurnHyperParameterTuning.TrainingJobSummaries[0].TrainingJobName'}, 'output/model.tar.gz']}}}], 'SupportedContentTypes': ['text/csv'], 'SupportedResponseMIMETypes': ['text/csv'], 'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium', 'ml.m5.xlarge'], 'SupportedTransformInstanceTypes': ['ml.m5.xlarge']}, 'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'}, 'SkipModelValidation': 'None'}}], 'ElseSteps': []}}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        auc_score_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_tuning, step_eval, step_cond],\n",
    ") \n",
    "definition = json.loads(pipeline.definition())\n",
    "print(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f590e057-150f-4190-980f-19f6cf4ede44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-east-1:640168443051:pipeline/sagemaker-mlops-train-pipeline/execution/t4ke8qrizpta', sagemaker_session=<sagemaker.session.Session object at 0x7fe615a3d340>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new or update existing Pipeline\n",
    "pipeline.upsert(role_arn=role)\n",
    "# start Pipeline execution\n",
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123c8ba-7572-437c-b621-5249f7ad0f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322ce66-f1e2-4ff9-9604-b46f83bee991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03869a3d-7ba1-4bbd-b7c1-3f932e386aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd8cf7-a4d6-4240-86a7-b6c1fd97cf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47ee3b-8b6e-4466-868d-763a314ec216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a04ea2-0109-4288-b358-fbea9d758078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb1441-49c8-4200-bd08-0770f1e59bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
